import torch
import os
import typing

def save_checkpoint(
    model: torch.nn.Module, 
    optimizer: torch.optim.Optimizer, 
    iteration: int, 
    out: typing.Union[str, os.PathLike, typing.BinaryIO, typing.IO[bytes]]
) -> None:
    """
    ä¿å­˜æ¨¡å‹æƒé‡ã€ä¼˜åŒ–å™¨çŠ¶æ€å’Œå½“å‰è¿­ä»£æ­¥æ•°åˆ°æŒ‡å®šè·¯å¾„æˆ–æ–‡ä»¶å¯¹è±¡ã€‚
    """
    # 1. æ„é€ ä¸€ä¸ªåŒ…å«æ‰€æœ‰å¿…è¦çŠ¶æ€çš„å¤§å­—å…¸
    checkpoint = {
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'iteration': iteration
    }
    
    # 2. ä½¿ç”¨ PyTorch çš„åºåˆ—åŒ–å·¥å…·ä¿å­˜åˆ°ç¡¬ç›˜
    torch.save(checkpoint, out)


def load_checkpoint(
    src: typing.Union[str, os.PathLike, typing.BinaryIO, typing.IO[bytes]], 
    model: torch.nn.Module, 
    optimizer: torch.optim.Optimizer
) -> int:
    """
    ä»æŒ‡å®šè·¯å¾„åŠ è½½çŠ¶æ€ï¼Œæ¢å¤æ¨¡å‹å’Œä¼˜åŒ–å™¨ï¼Œå¹¶è¿”å›ä¿å­˜æ—¶çš„è¿­ä»£æ­¥æ•°ã€‚
    """
    # 1. åŠ è½½å­—å…¸
    # ğŸ’¡ M1 Pro é¿å‘æŒ‡å—ï¼šä¸ºäº†é˜²æ­¢åœ¨ä¸åŒè®¾å¤‡é—´ç§»åŠ¨æƒé‡æ—¶æŠ¥é”™ï¼ˆæ¯”å¦‚åœ¨ CPU ä¸Šè¯»å– GPU å­˜çš„æƒé‡ï¼‰ï¼Œ
    # æœ€å¥½æ˜¾å¼åœ°å‘Šè¯‰ PyTorch æŠŠæƒé‡åŠ è½½åˆ°å½“å‰æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡ä¸Šã€‚
    # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ map_location å‚æ•°ï¼Œç¡®ä¿å®‰å…¨åŠ è½½ã€‚
    device = next(model.parameters()).device
    checkpoint = torch.load(src, map_location=device)
    
    # 2. æ¢å¤æ¨¡å‹å’Œä¼˜åŒ–å™¨çš„çŠ¶æ€
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    
    # 3. è¿”å›è®­ç»ƒè¿›åº¦
    return checkpoint['iteration']